{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0b6c28-2593-4f12-abf1-b07390565387",
   "metadata": {},
   "source": [
    "# Loading the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c5864-ceae-4152-81f0-7e3c225cdc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_raw = load_dataset(\"json\", data_files=\"./datasets/raw.jsonl\", split=\"train\")\n",
    "\n",
    "dataset_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff407ec",
   "metadata": {},
   "source": [
    "# Remove hh examples and type column\n",
    "\n",
    "The HH examples were not manually curated; they are exclusively positive examples extracted from high-throughput publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_formated = dataset_raw.filter(lambda x: x[\"type\"] == \"vh\").remove_columns(\n",
    "    [\"type\"]\n",
    ")\n",
    "\n",
    "dataset_formated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d6591",
   "metadata": {},
   "source": [
    "# Format the examples\n",
    "\n",
    "Several preprocessing steps are applied to the data:\n",
    "\n",
    "- Abstract paragraphs are joined into a single paragraph.\n",
    "- Unicode characters are unescaped (e.g., Greek letters in biomedical terms), and HTML tags are removed.\n",
    "- The number of words in the title, abstract, and the total word count are added for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b96cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# unescape html characters and remove html tags.\n",
    "format_text = lambda x: BeautifulSoup(html.unescape(x), \"html.parser\").get_text()\n",
    "\n",
    "\n",
    "def format_exemples(x):\n",
    "    # format title.\n",
    "    x[\"title\"] = format_text(x[\"title\"])\n",
    "    # replace the abstract part list by a string and format it.\n",
    "    x[\"abstract\"] = format_text(\" \".join(x[\"abstract\"]))\n",
    "    # add number of words in title and abstract.\n",
    "    title_num_words = len(x[\"title\"].split())\n",
    "    abstract_num_words = len(x[\"abstract\"].split())\n",
    "    x[\"title_num_words\"] = title_num_words\n",
    "    x[\"abstract_num_words\"] = abstract_num_words\n",
    "    x[\"total_num_words\"] = title_num_words + abstract_num_words\n",
    "    return x\n",
    "\n",
    "\n",
    "dataset_formatted = dataset_formated.map(format_exemples)\n",
    "\n",
    "dataset_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee6cd8",
   "metadata": {},
   "source": [
    "# Filter the dataset title and abstract size\n",
    "\n",
    "Only articles with a title and an abstract containing at least 30 words are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_examples(x):\n",
    "    if x[\"title_num_words\"] == 0:\n",
    "        return False\n",
    "    if x[\"abstract_num_words\"] < 30:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "dataset_formatted = dataset_formatted.filter(filter_examples)\n",
    "\n",
    "dataset_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68588ccb",
   "metadata": {},
   "source": [
    "# Inspect balance\n",
    "\n",
    "The dataset is highly unbalanced, with nearly 20 times more negative examples than positive ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# filters for each label.\n",
    "pos_filter = lambda x: x[\"is_selected\"]\n",
    "neg_filter = lambda x: not x[\"is_selected\"]\n",
    "\n",
    "pos = dataset_formatted.filter(pos_filter)\n",
    "neg = dataset_formatted.filter(neg_filter)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(\"Number of examples per label\")\n",
    "ax.pie([len(pos), len(neg)], labels=[f\"pos {len(pos)}\", f\"neg {len(neg)}\"])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cf1a49-a77e-44a6-8923-1a5d1ee63dc0",
   "metadata": {},
   "source": [
    "# Create train, eval and test splits\n",
    "\n",
    "- Evaluation and Test Splits: 10% of the dataset is randomly sampled twice to create evaluation and test splits. The original class imbalance is intentionally preserved to ensure that evaluations reflect real-world conditions.\n",
    "\n",
    "- Training Split: To fully utilize the negative examples, a synthetic balanced training split is created by repeating the positive examples approximately 20 times to match the number of negative examples. Training will be conducted over a single epoch, where each negative example appears once, while positive examples are repeated multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19830c-2fb1-412b-b4cc-495812830d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset, concatenate_datasets\n",
    "\n",
    "# helper function to split a given number (n: int) or by a given % (n: float).\n",
    "def split_dataset(d: Dataset, n: int | float, seed=42) -> tuple[Dataset, Dataset]:\n",
    "    splitted = d.train_test_split(n, seed=seed)\n",
    "    return splitted[\"train\"], splitted[\"test\"]\n",
    "\n",
    "\n",
    "# helper function to sample a dataset into train, eval and test datasets.\n",
    "def sample_dataset(dataset: Dataset, test_ratio: float = 0.1, seed=42) -> DatasetDict:\n",
    "    # get the examples of each label.\n",
    "    pos_train = dataset.filter(pos_filter)\n",
    "    neg_train = dataset.filter(neg_filter)\n",
    "\n",
    "    # total number in each split.\n",
    "    pos_num = len(pos_train)\n",
    "    neg_num = len(neg_train)\n",
    "\n",
    "    # test number for each split.\n",
    "    pos_num_test = int(pos_num * test_ratio)\n",
    "    neg_num_test = int(neg_num * test_ratio)\n",
    "\n",
    "    # get 10% of examples for test dataset.\n",
    "    pos_train, pos_test = split_dataset(pos_train, pos_num_test, seed)\n",
    "    neg_train, neg_test = split_dataset(neg_train, neg_num_test, seed)\n",
    "\n",
    "    # get 10% of examples for validation dataset.\n",
    "    pos_train, pos_eval = split_dataset(pos_train, pos_num_test, seed)\n",
    "    neg_train, neg_eval = split_dataset(neg_train, neg_num_test, seed)\n",
    "\n",
    "    # r = the number of time to repeat the positive train examples.\n",
    "    # extrapolate r times new examples from positive train exemples.\n",
    "    # concatenate all train datasets into a single one.\n",
    "    r = neg_num_test // pos_num_test\n",
    "    pos_train_list = [pos_train for _ in range(r)]\n",
    "    dataset_train = concatenate_datasets(pos_train_list + [neg_train]).shuffle(seed)\n",
    "\n",
    "    # create stratified eval and test datasets.\n",
    "    dataset_eval = concatenate_datasets([pos_eval, neg_eval]).shuffle(seed)\n",
    "    dataset_test = concatenate_datasets([pos_test, neg_test]).shuffle(seed)\n",
    "\n",
    "    # return a single dataset.\n",
    "    return DatasetDict(\n",
    "        {\n",
    "            \"train\": dataset_train,\n",
    "            \"eval\": dataset_eval,\n",
    "            \"test\": dataset_test,\n",
    "        }\n",
    "    )\n",
    "# sample train, eval and test datasets.\n",
    "dataset = sample_dataset(dataset_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c9ae1",
   "metadata": {},
   "source": [
    "# Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train = dataset[\"train\"].filter(pos_filter)\n",
    "neg_train = dataset[\"train\"].filter(neg_filter)\n",
    "pos_eval = dataset[\"eval\"].filter(pos_filter)\n",
    "neg_eval = dataset[\"eval\"].filter(neg_filter)\n",
    "pos_test = dataset[\"test\"].filter(pos_filter)\n",
    "neg_test = dataset[\"test\"].filter(neg_filter)\n",
    "\n",
    "print(len(pos_train), len(neg_train))\n",
    "print(pos_train[range(10)])\n",
    "print(neg_train[range(10)])\n",
    "\n",
    "print(len(pos_eval), len(neg_eval))\n",
    "print(pos_eval[range(10)])\n",
    "print(neg_eval[range(10)])\n",
    "\n",
    "print(len(pos_test), len(neg_test))\n",
    "print(pos_test[range(10)])\n",
    "print(neg_test[range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9a156",
   "metadata": {},
   "source": [
    "# Visualize the dataset\n",
    "\n",
    "The dataset splits align with expectations, and the word count distribution is similar across categories. Additionally, the mean word count is around 280 for each category, which is well-suited for language models handling sequences up to 512 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2771d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (pies, hists1, hists2) = plt.subplots(3, 3, figsize=(15, 7))\n",
    "\n",
    "# =========================\n",
    "pies[0].set_title(\"Train\")\n",
    "pies[0].pie(\n",
    "    [len(pos_train), len(neg_train)],\n",
    "    labels=[f\"pos {len(pos_train)}\", f\"neg {len(neg_train)}\"],\n",
    ")\n",
    "\n",
    "pies[1].set_title(\"Eval\")\n",
    "pies[1].pie(\n",
    "    [len(pos_eval), len(neg_eval)],\n",
    "    labels=[f\"pos {len(pos_eval)}\", f\"neg {len(neg_eval)}\"],\n",
    ")\n",
    "\n",
    "pies[2].set_title(\"Test\")\n",
    "pies[2].pie(\n",
    "    [len(pos_test), len(neg_test)],\n",
    "    labels=[f\"pos {len(pos_test)}\", f\"neg {len(neg_test)}\"],\n",
    ")\n",
    "\n",
    "# =========================\n",
    "hists1[0].set_ylim(0, 6000)\n",
    "hists1[0].set_title(\"Num words train pos\")\n",
    "\n",
    "x = pos_train[\"total_num_words\"]\n",
    "mean = np.mean(x)\n",
    "hists1[0].hist(x, histtype=\"bar\", range=(0, 500), bins=50)\n",
    "hists1[0].axvline(mean, color=\"r\", linestyle=\"--\")\n",
    "hists1[0].text(mean + mean / 20, 6000 * 0.8, f\"{mean:.2f}\", color=\"r\")\n",
    "\n",
    "hists1[1].set_ylim(0, 60)\n",
    "hists1[1].set_title(\"Num words eval pos\")\n",
    "\n",
    "x = pos_eval[\"total_num_words\"]\n",
    "mean = np.mean(x)\n",
    "hists1[1].hist(x, histtype=\"bar\", range=(0, 500), bins=50)\n",
    "hists1[1].axvline(mean, color=\"r\", linestyle=\"--\")\n",
    "hists1[1].text(mean + mean / 20, 60 * 0.8, f\"{mean:.2f}\", color=\"r\")\n",
    "\n",
    "hists1[2].set_ylim(0, 60)\n",
    "hists1[2].set_title(\"Num words test pos\")\n",
    "\n",
    "x = pos_test[\"total_num_words\"]\n",
    "mean = np.mean(x)\n",
    "hists1[2].hist(x, histtype=\"bar\", range=(0, 500), bins=50)\n",
    "hists1[2].axvline(mean, color=\"r\", linestyle=\"--\")\n",
    "hists1[2].text(mean + mean / 20, 60 * 0.8, f\"{mean:.2f}\", color=\"r\")\n",
    "\n",
    "# =========================\n",
    "hists2[0].set_ylim(0, 6000)\n",
    "hists2[0].set_title(\"Num words train neg\")\n",
    "\n",
    "x = neg_train[\"total_num_words\"]\n",
    "mean = np.mean(x)\n",
    "hists2[0].hist(x, histtype=\"bar\", range=(0, 500), bins=50)\n",
    "hists2[0].axvline(mean, color=\"r\", linestyle=\"--\")\n",
    "hists2[0].text(mean + mean / 20, 6000 * 0.8, f\"{mean:.2f}\", color=\"r\")\n",
    "\n",
    "hists2[1].set_ylim(0, 700)\n",
    "hists2[1].set_title(\"Num words eval neg\")\n",
    "\n",
    "x = neg_eval[\"total_num_words\"]\n",
    "mean = np.mean(x)\n",
    "hists2[1].hist(x, histtype=\"bar\", range=(0, 500), bins=50)\n",
    "hists2[1].axvline(mean, color=\"r\", linestyle=\"--\")\n",
    "hists2[1].text(mean + mean / 20, 700 * 0.8, f\"{mean:.2f}\", color=\"r\")\n",
    "\n",
    "hists2[2].set_ylim(0, 700)\n",
    "hists2[2].set_title(\"Num words test neg\")\n",
    "\n",
    "x = neg_test[\"total_num_words\"]\n",
    "mean = np.mean(x)\n",
    "hists2[2].hist(x, histtype=\"bar\", range=(0, 500), bins=50)\n",
    "hists2[2].axvline(mean, color=\"r\", linestyle=\"--\")\n",
    "hists2[2].text(mean + mean / 20, 700 * 0.8, f\"{mean:.2f}\", color=\"r\")\n",
    "\n",
    "# =========================\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2499e2db",
   "metadata": {},
   "source": [
    "# Save the dataset to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7827b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk(\"./datasets/abstracts.hf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
